#!/usr/bin/env python3
import os
import json
import sqlite3
import logging
import sys
import time
from dotenv import load_dotenv
from openai import OpenAI
from supabase import create_client

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
logger = logging.getLogger("drug_categorizer")

# Load environment variables
load_dotenv()

# Configuration
DB_FILE = "DB/pepsources.db"
CATEGORIZATION_BATCH_FILE = "DB/Batch_requests/drug_categorization_batch_input.jsonl"
CATEGORIZATION_OUTPUT_FILE = "DB/Batch_requests/drug_categorization_batch_output.jsonl"
CATEGORIZATION_MODEL = "gpt-4o"
CATEGORIZATION_MAX_TOKENS = 50

# OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Supabase client
SUPABASE_URL = os.getenv("VITE_SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("VITE_SUPABASE_SERVICE_KEY")

def validate_environment():
    """Validate all required environment variables are set."""
    missing_vars = []
    if not os.getenv("OPENAI_API_KEY"):
        missing_vars.append("OPENAI_API_KEY")
    if not SUPABASE_URL:
        missing_vars.append("VITE_SUPABASE_URL")
    if not SUPABASE_SERVICE_KEY:
        missing_vars.append("VITE_SUPABASE_SERVICE_KEY")
    
    if missing_vars:
        logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
        return False
    return True

def connect_supabase():
    """Connect to Supabase and return client."""
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
        logger.info("Connected to Supabase successfully")
        return supabase
    except Exception as e:
        logger.error(f"Failed to connect to Supabase: {e}")
        return None

def build_categorization_prompt(drug_name, proper_name, what_it_does, how_it_works):
    """
    Constructs a prompt for OpenAI to categorize a drug with a focus on human use cases.
    """
    prompt = f"""
Analyze the following research chemical/compound: {proper_name} (also known as {drug_name})

Information about the compound:
- What it does: {what_it_does}

Your task is to determine what a HUMAN would most likely use this compound for.
Categorize this based on the PRIMARY intended human use, not the mechanism of action.

Select EXACTLY two categories from the following list that best match what a human would use this for:
- Muscle Growth
- Anti-Inflammatory
- Peptide
- Recovery
- Weight Loss

Return your answer as a JSON object in this exact format:
{{"category1": "CATEGORY_NAME", "category2": "CATEGORY_NAME"}}

Choose the two most relevant categories from a human use perspective. If only one category strongly applies, use "General Research" as the second category.
"""
    return prompt

def clear_existing_categories(supabase_client):
    """Clear existing categories from Supabase database."""
    try:
        logger.info("Clearing existing categories from Supabase...")
        response = supabase_client.table("drugs").update({"alt_tag_1": None, "alt_tag_2": None}).execute()
        logger.info("Cleared categories in Supabase")
        
        # Also clear in SQLite
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute("UPDATE Drugs SET alt_tag_1 = NULL, alt_tag_2 = NULL")
        conn.commit()
        conn.close()
        logger.info("Cleared categories in SQLite")
        
        return True
    except Exception as e:
        logger.error(f"Error clearing categories: {e}")
        return False

def create_categorization_batch_requests():
    """
    Creates a JSONL batch file for drug categorizations.
    """
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    # Get all drugs that have descriptions
    cursor.execute("""
        SELECT id, name, proper_name, what_it_does, how_it_works 
        FROM Drugs 
        WHERE name IS NOT NULL AND proper_name IS NOT NULL
        AND what_it_does IS NOT NULL 
        ORDER BY id
    """)
    
    drugs = cursor.fetchall()
    conn.close()
    
    logger.info(f"Found {len(drugs)} drugs for categorization.")
    
    if not drugs:
        logger.info("No drugs found for categorization. Skipping batch creation.")
        return None

    tasks = []
    for drug in drugs:
        drug_id, name, proper_name, what_it_does, how_it_works = drug
        
        prompt = build_categorization_prompt(name, proper_name, what_it_does, how_it_works)
        custom_id = f"drug{drug_id}_categorization"
        
        logger.info(f"Creating batch request for drug ID {drug_id} ({proper_name}) categorization.")
        request_obj = {
            "custom_id": custom_id,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": CATEGORIZATION_MODEL,
                "messages": [
                    {"role": "system", "content": "You are a health researcher who understands how humans use supplements."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": CATEGORIZATION_MAX_TOKENS,
                "temperature": 0.2,
                "response_format": {"type": "json_object"}
            }
        }
        tasks.append(request_obj)
    
    total_requests = len(tasks)
    logger.info(f"Total categorization batch requests: {total_requests}")
    
    # Create directories if they don't exist
    os.makedirs(os.path.dirname(CATEGORIZATION_BATCH_FILE), exist_ok=True)
    
    try:
        with open(CATEGORIZATION_BATCH_FILE, "w", encoding="utf-8") as f:
            for task in tasks:
                json_line = json.dumps(task)
                f.write(json_line + "\n")
        logger.info(f"Categorization batch file '{CATEGORIZATION_BATCH_FILE}' created with {total_requests} requests.")
        return CATEGORIZATION_BATCH_FILE
    except Exception as e:
        logger.error(f"Error writing categorization batch file: {e}")
        return None

def upload_batch_file(file_path):
    """Upload batch file to OpenAI."""
    logger.info(f"Uploading batch file: {file_path}")
    with open(file_path, "rb") as f:
        batch_file = client.files.create(
            file=f,
            purpose="batch"
        )
    logger.info(f"Batch file uploaded. File ID: {batch_file.id}")
    return batch_file.id

def create_batch_job(input_file_id):
    """Create a batch job with OpenAI."""
    logger.info("Creating batch job...")
    batch_job = client.batches.create(
        input_file_id=input_file_id,
        endpoint="/v1/chat/completions",
        completion_window="24h"
    )
    logger.info(f"Batch job created. Job ID: {batch_job.id}, status: {batch_job.status}")
    return batch_job.id

def poll_batch_status(batch_job_id, poll_interval=10, timeout=360000):
    """Poll the status of a batch job until completion."""
    logger.info(f"Polling batch job status for job ID: {batch_job_id}")
    elapsed = 0
    while elapsed < timeout:
        current_job = client.batches.retrieve(batch_job_id)
        status = current_job.status
        logger.info(f"Batch job status: {status}")
        if status in ["completed", "failed", "expired"]:
            return current_job
        time.sleep(poll_interval)
        elapsed += poll_interval
    raise Exception("Batch job polling timed out.")

def retrieve_results(batch_job, output_file):
    """Retrieve and save batch job results."""
    if batch_job.status == "completed" and batch_job.output_file_id:
        logger.info(f"Retrieving results for batch job: {batch_job.id}")
        result_content = client.files.content(batch_job.output_file_id).content
        
        # Ensure directory exists
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, "wb") as f:
            f.write(result_content)
        logger.info(f"Results saved to '{output_file}'")
        return True
    else:
        logger.error(f"Batch job didn't complete successfully. Status: {batch_job.status}")
        return False

def update_drug_categories(drug_id, category1, category2, supabase_client):
    """
    Update the drug record with categorization in both local SQLite 
    and Supabase without changing the in_supabase flag.
    """
    # Update local SQLite DB
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    try:
        # Get current drug record (we need this for the Supabase upsert)
        cursor.execute("SELECT * FROM Drugs WHERE id = ?", (drug_id,))
        row = cursor.fetchone()
        
        if not row:
            logger.warning(f"No drug found with ID {drug_id}")
            conn.close()
            return False
        
        # Get the column names from cursor description
        cursor.execute("PRAGMA table_info(Drugs)")
        columns = [col[1] for col in cursor.fetchall()]
        
        # Create a dictionary of the current row data
        drug_dict = {columns[i]: row[i] for i in range(len(columns))}
        
        # Update the categories in the dictionary
        drug_dict['alt_tag_1'] = category1
        drug_dict['alt_tag_2'] = category2
        
        # Update the categories in the SQLite DB without changing in_supabase
        cursor.execute("""
            UPDATE Drugs 
            SET alt_tag_1 = ?, 
                alt_tag_2 = ?
            WHERE id = ?
        """, (category1, category2, drug_id))
        
        conn.commit()
        logger.info(f"Updated drug ID {drug_id} in SQLite with categories: {category1}, {category2}")
        
        # Now update Supabase directly
        try:
            # Remove 'id' from dict for upsert if it's None
            if drug_dict.get('id') is None:
                logger.warning(f"Drug ID is None for record {drug_id}, skipping Supabase update")
                return True
                
            # Make sure no None values are sent as they can cause issues with Postgres
            clean_dict = {k: (v if v is not None else "") for k, v in drug_dict.items()}
            
            supabase_response = supabase_client.table("drugs").upsert([clean_dict], on_conflict="id").execute()
            logger.info(f"Updated drug ID {drug_id} in Supabase")
            return True
        except Exception as e:
            logger.error(f"Error updating drug ID {drug_id} in Supabase: {e}")
            return False
            
    except sqlite3.Error as e:
        logger.error(f"Error updating drug ID {drug_id} with categories: {e}")
        conn.rollback()
        return False
    finally:
        conn.close()

def process_batch_results(batch_file, supabase_client):
    """Process the batch results file and update databases."""
    if not os.path.exists(batch_file):
        logger.error(f"Batch result file '{batch_file}' does not exist.")
        return 0

    with open(batch_file, "r", encoding="utf-8") as f:
        lines = f.readlines()

    total_lines = len(lines)
    logger.info(f"Found {total_lines} lines in batch results file.")
    
    processed_count = 0
    success_count = 0
    
    for i, line in enumerate(lines, 1):
        try:
            logger.info(f"Processing line {i} of {total_lines}")
            result = json.loads(line.strip())
            custom_id = result.get("custom_id", "")
            
            if not custom_id.startswith("drug") or "_categorization" not in custom_id:
                logger.warning(f"Invalid custom ID format: {custom_id}")
                continue
                
            drug_id_str = custom_id.split("_")[0].replace("drug", "")
            
            try:
                drug_id = int(drug_id_str)
            except ValueError:
                logger.warning(f"Could not parse drug ID from {drug_id_str}")
                continue
                
            # Check if there's an error in the response
            if result.get("error"):
                logger.warning(f"Error in response for {custom_id}: {result.get('error')}")
                continue
                
            response = result.get("response", {})
            if response.get("status_code") != 200:
                logger.warning(f"Request {custom_id} returned status {response.get('status_code')}")
                continue

            # Access the body directly from the response
            body = response.get("body", {})
            
            # Handle both string and dictionary body formats
            if isinstance(body, str):
                try:
                    body = json.loads(body)
                except json.JSONDecodeError:
                    logger.warning(f"Could not parse body JSON for {custom_id}")
                    continue
            
            choices = body.get("choices", [])
            if not choices or len(choices) == 0:
                logger.warning(f"No choices found in response for {custom_id}")
                continue
                
            message = choices[0].get("message", {})
            if not message:
                logger.warning(f"No message found in response for {custom_id}")
                continue

            content = message.get("content", "")
            if not content:
                logger.warning(f"Empty content in message for {custom_id}")
                continue
            
            try:
                # Print the raw content for debugging
                logger.info(f"Raw content for drug {drug_id}: {content}")
                
                categories = json.loads(content)
                category1 = categories.get("category1", "Unknown")
                category2 = categories.get("category2", "General Research")
                
                # Normalize category names
                category1 = category1.strip()
                category2 = category2.strip()
                
                logger.info(f"Drug ID {drug_id}: Parsed categories - {category1}, {category2}")
                
                if update_drug_categories(drug_id, category1, category2, supabase_client):
                    success_count += 1
                    
                processed_count += 1
                
            except json.JSONDecodeError as e:
                logger.warning(f"Could not parse JSON from response content: {e}. Content: {content[:100]}...")
            
        except Exception as e:
            logger.error(f"Error processing categorization line: {e}")
            import traceback
            logger.error(traceback.format_exc())

    logger.info(f"Processed {processed_count} categorization results. Successfully updated {success_count} drugs.")
    return success_count

def run_categorization_batch(clear_categories=False):
    """Run the complete drug categorization batch process."""
    try:
        # Validate environment
        if not validate_environment():
            logger.error("Environment validation failed. Exiting.")
            return 0
        
        # Connect to Supabase
        supabase_client = connect_supabase()
        if not supabase_client:
            logger.error("Failed to connect to Supabase. Exiting.")
            return 0
            
        # Clear existing categories if requested
        if clear_categories:
            if not clear_existing_categories(supabase_client):
                logger.error("Failed to clear existing categories. Continuing anyway...")
        
        # Create the batch file
        batch_file = create_categorization_batch_requests()
        if not batch_file:
            logger.info("No categorization batch file created. Process complete.")
            return 0
            
        # Upload and process the batch
        input_file_id = upload_batch_file(batch_file)
        batch_job_id = create_batch_job(input_file_id)
        final_job = poll_batch_status(batch_job_id)
        
        if retrieve_results(final_job, CATEGORIZATION_OUTPUT_FILE):
            processed_count = process_batch_results(CATEGORIZATION_OUTPUT_FILE, supabase_client)
            logger.info(f"Categorization batch process completed. Processed {processed_count} drugs.")
            return processed_count
        else:
            logger.error("Failed to retrieve categorization results.")
            return 0
    except Exception as e:
        logger.error(f"Error during categorization batch process: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0

def process_existing_results(batch_file=None):
    """Process existing batch results file."""
    try:
        # Validate environment
        if not validate_environment():
            logger.error("Environment validation failed. Exiting.")
            return 0
        
        # Connect to Supabase
        supabase_client = connect_supabase()
        if not supabase_client:
            logger.error("Failed to connect to Supabase. Exiting.")
            return 0
            
        # Use the provided batch file or default
        output_file = batch_file or CATEGORIZATION_OUTPUT_FILE
        
        logger.info(f"Processing existing batch results from {output_file}")
        processed_count = process_batch_results(output_file, supabase_client)
        logger.info(f"Batch processing completed. Updated {processed_count} drugs.")
        return processed_count
    except Exception as e:
        logger.error(f"Error processing existing results: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0

def main():
    """Main function to run the drug categorizer."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Drug Categorizer')
    parser.add_argument('--clear', action='store_true', help='Clear existing categories before processing')
    parser.add_argument('--process-only', action='store_true', help='Process existing batch results without running a new batch')
    parser.add_argument('--batch-file', type=str, help='Custom batch results file to process')
    
    args = parser.parse_args()
    
    if args.process_only:
        # Only process existing results
        return process_existing_results(args.batch_file)
    else:
        # Run the full batch process
        return run_categorization_batch(clear_categories=args.clear)

if __name__ == "__main__":
    try:
        success_count = main()
        logger.info(f"Process complete. Successfully processed {success_count} records.")
        sys.exit(0 if success_count > 0 else 1)
    except KeyboardInterrupt:
        logger.info("Process interrupted by user.")
        sys.exit(130)
    except Exception as e:
        logger.error(f"Fatal error in categorization process: {e}", exc_info=True)
        sys.exit(1)