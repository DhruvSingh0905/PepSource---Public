import time
import sqlite3
import torch
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from fake_useragent import UserAgent
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import re

# Set up the BERT model for drug name extraction
MODEL_NAME = "jsylee/scibert_scivocab_uncased-finetuned-ner"
ID2LABEL = {0: 'O', 1: 'B-DRUG', 2: 'I-DRUG', 3: 'B-EFFECT', 4: 'I-EFFECT'}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForTokenClassification.from_pretrained(
        MODEL_NAME,
        num_labels=len(ID2LABEL),
        id2label=ID2LABEL
    ).to(device)
    model.eval()

    nlp_pipeline = pipeline(
        task="ner",
        model=model,
        tokenizer=tokenizer,
        device=0 if torch.cuda.is_available() else -1,
        aggregation_strategy="simple",
    )
    # Warm-up inference
    print("Warming up the NER pipeline with a dummy inference...")
    _ = nlp_pipeline("This is a dummy warm-up pass.")
    print("Model pipeline loaded and warmed up successfully.")
except Exception as e:
    print(f"Error setting up BERT model: {e}")

# Function to truncate text for BERT
def truncate_text_for_model(text, max_length=512):
    inputs = tokenizer(
        text, return_tensors="pt", truncation=True, max_length=max_length, padding="max_length"
    )
    return tokenizer.decode(inputs["input_ids"][0], skip_special_tokens=True)

# Function to extract drug names using BERT
# Removes size information if it is incorrectly included in the drug name
def extract_drugs(text):
    truncated = truncate_text_for_model(text)
    entities = nlp_pipeline(truncated)
    drugs = []
    for ent in entities:
        if ent["entity_group"] == "DRUG":
            drug_name = ent["word"]
            # Remove size (e.g., "100mg" or "100 IU") from the drug name
            drug_name = re.sub(r"\b\d+\s*(mg|IU)\b", "", drug_name, flags=re.IGNORECASE).strip()
            drugs.append(drug_name)
    return drugs[:2]  # Return at most two drug names

# Function to extract size (e.g., "100mg" or "100 IU") from text
def extract_size(text):
    match = re.search(r"\b(\d+)\s*(mg|IU)\b", text, re.IGNORECASE)
    return match.group(0) if match else None

# Function to configure Selenium with a fake user agent
def configure_selenium():
    ua = UserAgent()
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument(f"--user-agent={ua.random}")

    driver = webdriver.Chrome(options=options)
    driver.implicitly_wait(5)
    return driver

# Initialize Selenium WebDriver
service = Service('/path/to/chromedriver')  # Update with your chromedriver path
driver = configure_selenium()

# Base URL for SwissChems shop
BASE_URL = "https://swisschems.is/shop/"

# Set up SQLite database
conn = sqlite3.connect("pepsources.db")
cursor = conn.cursor()

# Create tables
cursor.execute("""
CREATE TABLE IF NOT EXISTS Drugs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT UNIQUE,
    alt_name TEXT
)
""")

cursor.execute("""
CREATE TABLE IF NOT EXISTS Vendors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT,
    product_name TEXT,
    product_link TEXT,
    product_image TEXT,
    price TEXT,
    size TEXT,
    drug_id INTEGER,
    FOREIGN KEY (drug_id) REFERENCES Drugs (id)
)
""")

conn.commit()

# Function to extract product details from a single page
def scrape_page(url):
    print(f"Scraping URL: {url}")
    driver.get(url)
    time.sleep(3)  # Allow the page to load fully

    product_elements = driver.find_elements(By.CLASS_NAME, "product.type-product")

    for product in product_elements:
        try:
            # Extract product page link
            wrapper = product.find_element(By.CLASS_NAME, "woocommerce-image__wrapper")
            product_link = wrapper.find_element(By.TAG_NAME, "a").get_attribute("href")

            # Extract product image
            product_image = product.find_element(By.TAG_NAME, "img").get_attribute("src")

            # Extract product name and size
            product_title_element = product.find_element(By.CLASS_NAME, "woocommerce-loop-product__title")
            product_name = product_title_element.find_element(By.TAG_NAME, "a").text.strip()

            # Extract size
            product_size = extract_size(product_name)

            # Extract price (newest price only)
            price_element = product.find_element(By.CLASS_NAME, "price")
            current_price = price_element.find_element(By.TAG_NAME, "ins").text.strip() if "ins" in price_element.get_attribute("innerHTML") else price_element.text.strip()

            # Extract drug names using BERT model
            extracted_drugs = extract_drugs(product_name)
            primary_drug = extracted_drugs[0] if extracted_drugs else "Unknown"
            alt_drug = extracted_drugs[1] if len(extracted_drugs) > 1 else None

            # Insert or update drug information
            cursor.execute("INSERT OR IGNORE INTO Drugs (name, alt_name) VALUES (?, ?)", (primary_drug, alt_drug))
            conn.commit()

            # Get drug ID
            cursor.execute("SELECT id FROM Drugs WHERE name = ?", (primary_drug,))
            drug_id = cursor.fetchone()[0]

            # Store product information in the Vendors table
            cursor.execute(
                """
                INSERT INTO Vendors (name, product_name, product_link, product_image, price, size, drug_id)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                """,
                ("SwissChems", product_name, product_link, product_image, current_price, product_size, drug_id)
            )
            conn.commit()

            print(f"Added product: {product_name}, Size: {product_size}, under drug: {primary_drug}, Alt drug: {alt_drug}")

        except Exception as e:
            print(f"Error extracting product details: {e}")

# Function to scrape all pages
def scrape_all_pages():
    page_url = BASE_URL
    page_number = 1

    while page_url:
        print(f"Scraping page {page_number}...")
        scrape_page(page_url)

        # Find next page link
        try:
            next_button = driver.find_element(By.CLASS_NAME, "next.page-numbers")
            page_url = next_button.get_attribute("href")
        except Exception:
            page_url = None

        page_number += 1
        time.sleep(3 + (page_number % 5))  # Randomized delay to reduce bot detection

# Run the scraper
scrape_all_pages()

print("Scraping complete. Data saved to SQLite database.")

# Close the driver and database connection
driver.quit()
conn.close()
